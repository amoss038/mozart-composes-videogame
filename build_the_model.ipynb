{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_self_attention import SeqSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "import pickle\n",
    "from keras.layers import TimeDistributed\n",
    "from preprocessing import prepare_notes\n",
    "\n",
    "##need to upgrade tensorflow to use SeqSelfAttention\n",
    "#from tensorflow.keras.layers import SeqSelfAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First simple model to get MVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking function\n",
    "lstm_input, lstm_output = prepare_notes()\n",
    "lstm_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are several different note files, make sure creating inputs from same note file **\n",
    "pickle_file = open(\"data/notes\", \"rb\")\n",
    "notes = pickle.load(pickle_file)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking VOCAB --> This changed when transposing be careful. Make sure LSTM inputs match\n",
    "VOCAB = (len(set(notes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(lstm_input):\n",
    "    '''\n",
    "    Build and compile the model\n",
    "    \n",
    "    lstm_input: lstm_input.shape[1] = number of steps, lstm_input.shape[2] = number features needed for\n",
    "    Bi-directional\n",
    "    \n",
    "    model_output: number of categories to output for classification\n",
    "    \n",
    "    returns: compiled model\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(512,input_shape=(lstm_input.shape[1], lstm_input.shape[2]), return_sequences=True)))\n",
    "    model.add(SeqSelfAttention(attention_width = 100 , attention_activation='sigmoid'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(512, return_sequences=True)))\n",
    "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(512, return_sequences=False)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(VOCAB))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, lstm_input, lstm_output):\n",
    "    '''\n",
    "    fit model and save checkpoint\n",
    "    \n",
    "    model: lstm model from function build_model()\n",
    "    lstm_input: input to the model- output from function prepare_notes() \n",
    "    lstm_output: targets for model- output from function prepare_notes()\n",
    "    \n",
    "    returns: None\n",
    "    '''\n",
    "    \n",
    "    # checkpoint\n",
    "    filepath=\"checkpoint/weights-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "    #only 10 epochs to start and see if the model works\n",
    "    model.fit(lstm_input, lstm_output, epochs=1, batch_size=64, callbacks=callbacks_list)\n",
    "    model.save_weights('first_train.h5')\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(vocab):\n",
    "    '''\n",
    "    calls the prepare notes function\n",
    "    calls the build model function \n",
    "    calls the fit_model function \n",
    "    '''\n",
    "    lstm_input, lstm_output = prepare_notes()\n",
    "    model = build_model(lstm_input)\n",
    "    fit_model(model, lstm_input, lstm_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Always Making Sure Data Matches \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train(VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all pitch names\n",
    "pitchnames = sorted(set(item for item in notes))\n",
    "# Get all pitch names\n",
    "n_vocab = len(set(notes))\n",
    "    \n",
    "#print(pitchnames)\n",
    "print(n_vocab)\n",
    "#print(notes)\n",
    "print(len(notes))\n",
    "\n",
    "#print(lstm_input[1])\n",
    "print(lstm_input.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
