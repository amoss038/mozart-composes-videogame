{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from preprocessing import prepare_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First simple model to get MVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = 2508"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(lstm_input, model_output):\n",
    "    '''\n",
    "    Build and compile the model\n",
    "    \n",
    "    lstm_input: lstm_input.shape[1] = number of steps, lstm_input.shape[2] = number features needed for\n",
    "    Bi-directional\n",
    "    \n",
    "    model_output: number of categories to output for classification\n",
    "    \n",
    "    returns: compiled model\n",
    "    '''\n",
    "    lstm_input, lstm_output = prepare_notes(notes)\n",
    "    \n",
    "    model = Sequential()\n",
    "    forward_layer = LSTM(512, return_sequences=True)\n",
    "    backward_layer = LSTM(512, activation='sigmoid', return_sequences=True,\n",
    "                       go_backwards=True)\n",
    "    model.add(Bidirectional(forward_layer, backward_layer=backward_layer,\n",
    "                         input_shape=(lstm_input.shape[1], lstm_input.shape[2])))\n",
    "    model.add(Dense(VOCAB))\n",
    "    \n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    \n",
    "    model\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, lstm_input, lstm_output):\n",
    "    '''\n",
    "    fit model and save checkpoint\n",
    "    \n",
    "    model: lstm model from function build_model()\n",
    "    lstm_input: input to the model- output from function prepare_notes() \n",
    "    lstm_output: targets for model- output from function prepare_notes()\n",
    "    \n",
    "    returns: None\n",
    "    '''\n",
    "    # checkpoint\n",
    "    filepath=\"checkpoint/weights-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    model.fit(lstm_input, lstm_output, epochs=200, batch_size=64, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
