{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "from music21 import converter, instrument, stream, note, chord\n",
    "\n",
    "#Run version 2.1.6\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation, Bidirectional, Flatten\n",
    "from keras import utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras_self_attention import SeqSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = open(\"data/notes\", \"rb\")\n",
    "notes = pickle.load(pickle_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = (len(set(notes)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(lstm_input):\n",
    "    '''\n",
    "    Build and compile the model\n",
    "    \n",
    "    lstm_input: lstm_input.shape[1] = number of steps, lstm_input.shape[2] = number features needed for\n",
    "    Bi-directional\n",
    "    \n",
    "    **Uses constant VOCAB for the dense layer**--> number of unique notes\n",
    "    \n",
    "    returns: compiled model with all the weights from trained model\n",
    "    '''\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(512,input_shape=(lstm_input.shape[1], lstm_input.shape[2]), return_sequences=True)))\n",
    "    model.add(SeqSelfAttention(attention_width=15, attention_activation='sigmoid'))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(512,input_shape=(lstm_input.shape[1], lstm_input.shape[2]), return_sequences=True)))\n",
    "    model.add(SeqSelfAttention(attention_width=15, attention_activation='sigmoid'))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(512,input_shape=(lstm_input.shape[1], lstm_input.shape[2]), return_sequences=True)))\n",
    "    model.add(SeqSelfAttention(attention_width=15, attention_activation='sigmoid'))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(VOCAB))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    \n",
    "    #model.load_weights(Path/to/weight--- > finish after training)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_notes():\n",
    "    '''\n",
    "    prepare lstm input notes again used by the network to predict notes\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    pickle_file = open(\"data/notes\", \"rb\")\n",
    "    notes = pickle.load(pickle_file)\n",
    "    #setting the sequence length to 100\n",
    "    #print(len(set(notes)))\n",
    "    sequence = 100 \n",
    "    #creating all the unique notes for create the dictionary from\n",
    "    pitches = sorted(set(note for note in notes))\n",
    "    \n",
    "    #creating the note to int dict to map pitches to integers\n",
    "    note_dict = dict((note, number) for number, note in enumerate(pitches))\n",
    "    #print(note_dict)\n",
    "    lstm_input = []\n",
    "    lstm_output = []\n",
    "    \n",
    "    #creating inputs and corresponding outputs\n",
    "    for i in range(0, len(notes)- sequence, 1):\n",
    "        inputs = notes[i : i + sequence]\n",
    "        outputs = notes[i + sequence]\n",
    "        lstm_input.append([note_dict[pitch] for pitch in inputs])\n",
    "        lstm_output.append(note_dict[outputs])\n",
    "    \n",
    "    #creating all the objects to reshape network input to make compatable with lstm network\n",
    "    shape_1 = lstm_input\n",
    "    shape_2 = len(lstm_input)\n",
    "    shape_3 = sequence \n",
    "    \n",
    "    #reshaping lstm input for lstm\n",
    "    lstm_input = np.reshape(shape_1, (shape_2, shape_3, 1))\n",
    "    \n",
    "    #normalize lstm input with  number of unique notes\n",
    "    lstm_normalized = lstm_input / float(len(pitches))\n",
    "    \n",
    "    return lstm_input, lstm_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_to_notes(model, lstm_input, pitches, VOCAB):\n",
    "    '''\n",
    "    **Generated predictions from model based on random starting point**\n",
    "    \n",
    "    model: --> Original model with weights loaded\n",
    "    lstm_inputL: --> Output from prepare, used to initialize pattern with an int the model recognizes\n",
    "    pitches: ---> list of all the notes, chords and rests\n",
    "    VOCAB:----> Number of unique notes to classify = len(pitches)\n",
    "    \n",
    "    output: Predicted_notes \n",
    "    '''\n",
    "    #random starting point \n",
    "    start = np.random.randit(0, len(lstm_input) -1)\n",
    "    \n",
    "    note_dict = dict((note, number) for number, note in enumerate(pitches))\n",
    "    \n",
    "    pattern - lstm_input[start]\n",
    "    predicted_notes = []\n",
    "    \n",
    "    for note in range(500):\n",
    "        to_predict = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        to_predict = to_predict/ float(VOCAB)\n",
    "        \n",
    "        prediction = model.predict(to_predict, verbose = 0)\n",
    "        \n",
    "        index = np.argmax(prediction)\n",
    "        result =note_dict[index]\n",
    "        predicted_notes.append(result)\n",
    "        \n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "        \n",
    "    return predicted_notes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_convert(predicted_notes):\n",
    "    '''\n",
    "    convert the notes in predicted_notes to midi files\n",
    "    \n",
    "    predicted_notes: Output from function predict_to_notes() --> list of predicted notes\n",
    "    \n",
    "    returns: None --- > Creates a midi file when ran\n",
    "    '''\n",
    "    offset = 0 \n",
    "    midi_notes = []\n",
    "    \n",
    "    #create notes, chords, and rest objects from predicted_notes\n",
    "    for pattern in predicted_notes:\n",
    "        pattern = pattern.split()\n",
    "        temp = pattern[0]\n",
    "        duration = pattern[1]\n",
    "        pattern = temp\n",
    "        #checking to see if a note is a chord \n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in chord:\n",
    "                this_note = note.Note(int(current_note))\n",
    "                this_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(this_note)\n",
    "            new_chord = chord.Chord(notes) \n",
    "            new_chord.offset = offset\n",
    "            midi_notes.append(new_chord)\n",
    "        #if the pattern is a rest    \n",
    "        elif ('rest' in pattern):\n",
    "            this_rest = note.Rest(pattern)\n",
    "            this_rest.offset = offset\n",
    "            this_rest.storedInstrument = instrument.Piano() #Still needs to be paino instrument even though = rest\n",
    "            midi_notes.append(this_rest)\n",
    "        else:\n",
    "            this_note = note.Note(pattern)\n",
    "            this_notes.offset = offset \n",
    "            this_notes.storedInstrument = instrument.Piano()\n",
    "            midi_notes.append(this_note)\n",
    "        #ensure that the notes do not stack    \n",
    "        offset += convert_to_float(duration)\n",
    "    \n",
    "    midi = stream.Stream(midi_notes)\n",
    "    midi.write('midi', fp = 'predicted_song.mid')\n",
    "    \n",
    "    \n",
    "#From: https://stackoverflow.com/questions/1806278/convert-fraction-to-float\n",
    "def convert_to_float(frac_str):\n",
    "    try:\n",
    "        return float(frac_str)\n",
    "    except ValueError:\n",
    "        num, denom = frac_str.split('/')\n",
    "        try:\n",
    "            leading, num = num.split(' ')\n",
    "            whole = float(leading)\n",
    "        except ValueError:\n",
    "            whole = 0\n",
    "        frac = float(num) / float(denom)\n",
    "        return whole - frac if whole < 0 else whole + frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
