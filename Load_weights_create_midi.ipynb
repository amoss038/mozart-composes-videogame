{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import keras\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "from music21 import converter, instrument, stream, note, chord\n",
    "import tensorflow as tf\n",
    "import music21 as m21\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation, Bidirectional, Flatten\n",
    "from keras import utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from tensorflow.keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the architecture of the network with the lowest error \n",
    "# Notice the attention width is the same as input sequence\n",
    "def build_model(lstm_input):\n",
    "    '''\n",
    "    Build and compile the model\n",
    "    \n",
    "    lstm_input: lstm_input.shape[1] = number of steps, lstm_input.shape[2] = number features needed for\n",
    "    Bi-directional\n",
    "    \n",
    "    model_output: number of categories to output for classification\n",
    "    \n",
    "    returns: compiled model\n",
    "    '''\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(512,input_shape=(lstm_input.shape[1], lstm_input.shape[2]), return_sequences=True)))\n",
    "    model.add(SeqSelfAttention(attention_width = 100 , attention_activation='sigmoid'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.add(Bidirectional(LSTM(512, return_sequences=True)))\n",
    "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(512, return_sequences=False)))\n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(VOCAB))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    \n",
    "    #model.load_weights('models_weights/weights_attention.h5')\n",
    "    return model\n",
    "# Load the model first -- >tf.keras.models.load_model((path),custom_objects={'SeqSelfAttention': SeqSelfAttention})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_notes(notes, pitches, VOCAB):\n",
    "    '''\n",
    "    prepare lstm input notes again used by the network to predict notes\n",
    "    \n",
    "    '''\n",
    "    #setting the sequence length to 100\n",
    "    #print(len(set(notes)))\n",
    "    sequence = 100 \n",
    "    \n",
    "    #creating the note to int dict to map pitches to integers\n",
    "    note_dict = dict((note, number) for number, note in enumerate(pitches))\n",
    "    #print(note_dict)\n",
    "    lstm_input = []\n",
    "    lstm_output = []\n",
    "    \n",
    "    #creating inputs and corresponding outputs\n",
    "    for i in range(0, len(notes)- sequence, 1):\n",
    "        inputs = notes[i : i + sequence]\n",
    "        outputs = notes[i + sequence]\n",
    "        lstm_input.append([note_dict[pitch] for pitch in inputs])\n",
    "        lstm_output.append(note_dict[outputs])\n",
    "    \n",
    "    #creating all the objects to reshape network input to make compatable with lstm network\n",
    "    shape_1 = lstm_input\n",
    "    shape_2 = len(lstm_input)\n",
    "    shape_3 = sequence \n",
    "    \n",
    "    #reshaping lstm input for lstm\n",
    "    lstm_input = np.reshape(shape_1, (shape_2, shape_3, 1))\n",
    "    \n",
    "    #normalize lstm input with  number of unique notes\n",
    "    lstm_normalized = lstm_input / float(len(pitches))\n",
    "    \n",
    "    return (lstm_input, lstm_normalized)\n",
    "lstm_input, lstm_normalized = prepare_notes(notes, pitches, VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_to_notes(model, lstm_input, pitches, VOCAB):\n",
    "    '''\n",
    "    **Generated predictions from model based on random starting point**\n",
    "    \n",
    "    model: --> Original model with weights loaded\n",
    "    lstm_inputL: --> Output from prepare, used to initialize pattern with an int the model recognizes\n",
    "    pitches: ---> list of all the notes, chords and rests\n",
    "    VOCAB:----> Number of unique notes to classify = len(pitches)\n",
    "    \n",
    "    output: Predicted_notes \n",
    "    '''\n",
    "    #random starting point \n",
    "    start = np.random.randint(0, len(lstm_input) -1)\n",
    "    note_dict = dict((number, note) for number, note in enumerate(pitches))\n",
    "    \n",
    "    pattern = lstm_input[start]\n",
    "    print(type(pattern))\n",
    "   \n",
    "    predicted_notes = []\n",
    "    \n",
    "    \n",
    "    for note in range(500):\n",
    "        to_predict = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        to_predict = to_predict/ float(VOCAB)\n",
    "        #print(to_predict.shape)\n",
    "        \n",
    "        prediction = model.predict(to_predict, verbose = 0)\n",
    "        #print(type(prediction))\n",
    "        index = np.argmax(prediction)\n",
    "        print(index)\n",
    "        \n",
    "        result = note_dict[index]\n",
    "        predicted_notes.append(result)\n",
    "        \n",
    "        pattern = np.append(pattern, index)\n",
    "        print(pattern)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "        \n",
    "    return predicted_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_convert(predicted_notes):\n",
    "    '''\n",
    "    convert the notes in predicted_notes to midi files\n",
    "    \n",
    "    predicted_notes: Output from function predict_to_notes() --> list of predicted notes\n",
    "    \n",
    "    returns: None --- > Creates a midi file when ran\n",
    "    '''\n",
    "    offset = 0 \n",
    "    midi_notes = []\n",
    "    \n",
    "    #create notes, chords, and rest objects from predicted_notes\n",
    "    for pattern in predicted_notes:\n",
    "        pattern = pattern.split(' ')\n",
    "        print(pattern)\n",
    "        temp = pattern[0]\n",
    "        duration = pattern[1]\n",
    "        pattern = temp\n",
    "        #checking to see if a note is a chord \n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            chord_notes = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in chord_notes:\n",
    "                this_note = note.Note(int(current_note))\n",
    "                this_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(this_note)\n",
    "            new_chord = chord.Chord(notes) \n",
    "            new_chord.offset = offset\n",
    "            midi_notes.append(new_chord)\n",
    "        #if the pattern is a rest    \n",
    "        elif ('rest' in pattern):\n",
    "            this_rest = note.Rest(pattern)\n",
    "            this_rest.offset = offset\n",
    "            this_rest.storedInstrument = instrument.Piano() #Still needs to be paino instrument even though = rest\n",
    "            midi_notes.append(this_rest)\n",
    "        else:\n",
    "            this_note = note.Note(pattern)\n",
    "            this_note.offset = offset \n",
    "            this_note.storedInstrument = instrument.Piano()\n",
    "            midi_notes.append(this_note)\n",
    "        #ensure that the notes do not stack    \n",
    "        offset += convert_to_float(duration)\n",
    "    \n",
    "    midi = stream.Stream(midi_notes)\n",
    "    midi.write('midi', fp = 'midi_output/new_try.mid')\n",
    "    \n",
    "    \n",
    "#From: https://stackoverflow.com/questions/1806278/convert-fraction-to-float\n",
    "def convert_to_float(frac_str):\n",
    "    try:\n",
    "        return float(frac_str)\n",
    "    except ValueError:\n",
    "        num, denom = frac_str.split('/')\n",
    "        try:\n",
    "            leading, num = num.split(' ')\n",
    "            whole = float(leading)\n",
    "        except ValueError:\n",
    "            whole = 0\n",
    "        frac = float(num) / float(denom)\n",
    "        return whole - frac if whole < 0 else whole + frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    '''\n",
    "    generates the midi file\n",
    "    \n",
    "    \n",
    "    \n",
    "    output:None ---> creates the midi file\n",
    "    \n",
    "    '''\n",
    "    #Load the notes\n",
    "    pickle_file = open(\"data/notes\", \"rb\")\n",
    "    notes = pickle.load(pickle_file)\n",
    "    \n",
    "    #create the pitchnames\n",
    "    pitches = sorted(set(note for note in notes))\n",
    "    \n",
    "    \n",
    "    lstm_input, lstm_normalized = prepare_notes(notes, pitches, VOCAB) \n",
    "    model = tf.keras.models.load_model('models_weights/time_dist_no_attention.h5')\n",
    "    model.load_weights('models_weights/weights_no_attentnion.hdf5)\n",
    "    predicted_notes = predict_to_notes(model, lstm_input, pitches, VOCAB)\n",
    "    midi_convert(predicted_notes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('models_weights/weights_no_attentnion.hdf5')\n",
    "#model = tf.keras.models.load_model('models_weights/attention_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model('models_weights/time_dist_no_attention.h5')\n",
    "path = 'models_weights/Attention_model_legit.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model((path),custom_objects={'SeqSelfAttention': SeqSelfAttention})\n",
    "model.load_weights('models_weights/Attention_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#midi_convert(predicted_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TESTING ##\n",
    "pickle_file = open(\"data/notes\", \"rb\")\n",
    "notes = pickle.load(pickle_file)\n",
    "\n",
    "#using these just to test\n",
    "VOCAB = (len(set(notes)))\n",
    "pitches = sorted(set(note for note in notes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
